{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... read data\n",
      "(13500, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfqlQhl8qlOGXCmX4pUL9PyJdwaoBM+hBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bb17080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Model\n",
    "from utils import *\n",
    "from tensorboard_evaluation import Evaluation\n",
    "\n",
    "def read_data(datasets_dir=\"./data\", frac = 0.1):\n",
    "    \"\"\"\n",
    "    This method reads the states and actions recorded in drive_manually.py \n",
    "    and splits it into training/ validation set.\n",
    "    \"\"\"\n",
    "    print(\"... read data\")\n",
    "    data_file = os.path.join(datasets_dir, 'data.pkl.gzip')\n",
    "  \n",
    "    f = gzip.open(data_file,'rb')\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    # get images as features and actions as targets\n",
    "    X = np.array(data[\"state\"]).astype('float32')\n",
    "    y = np.array(data[\"action\"]).astype('float32')\n",
    "\n",
    "    # split data into training and validation set\n",
    "    n_samples = len(data[\"state\"])\n",
    "    X_train, y_train = X[:int((1-frac) * n_samples)], y[:int((1-frac) * n_samples)]\n",
    "    X_valid, y_valid = X[int((1-frac) * n_samples):], y[int((1-frac) * n_samples):]\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def preprocessing(X_train, y_train, X_valid, y_valid, history_length=1):\n",
    "\n",
    "    # TODO: preprocess your data here.\n",
    "    # 1. convert the images in X_train/X_valid to gray scale. If you use rgb2gray() from utils.py, the output shape (96, 96, 1)\n",
    "    # 2. you can either train your model with continous actions (as you get them from read_data) using regression\n",
    "    #    or you discretize the action space using action_to_id() from utils.py. If you discretize them, you'll maybe find one_hot() \n",
    "    #    useful and you may want to return X_train_unhot ... as well.\n",
    "    X_train = rgb2gray(X_train)\n",
    "    X_valid = rgb2gray(X_valid)\n",
    "    # history:\n",
    "    X_train_history = np.zeros((X_train.shape[0]-history_length+1, history_length, X_train.shape[1], X_train.shape[2]))\n",
    "    for i in range(X_train_history.shape[0]):\n",
    "        X_train_history[i] = X_train[i:i+history_length,:,:]\n",
    "    X_train_history = X_train_history.transpose(0,2,3,1)\n",
    "    \n",
    "    X_valid_history = np.zeros((X_valid.shape[0]-history_length+1, history_length, X_valid.shape[1], X_valid.shape[2]))\n",
    "    for i in range(X_valid_history.shape[0]):\n",
    "        X_valid_history[i] = X_valid[i:i+history_length,:,:]\n",
    "    X_valid_history = X_valid_history.transpose(0,2,3,1)\n",
    "    \n",
    "    # discretize actions\n",
    "    y_train_id = np.zeros(y_train.shape[0])\n",
    "    y_valid_id = np.zeros(y_valid.shape[0])\n",
    "    \n",
    "    for i in range(y_train.shape[0]):\n",
    "        y_train_id[i] = action_to_id(y_train[i])\n",
    "    for j in range(y_valid.shape[0]):\n",
    "        y_valid_id[j] = int(action_to_id(y_valid[j]))\n",
    "    y_train_id = y_train_id.astype(int)\n",
    "    y_valid_id = y_valid_id.astype(int)\n",
    "    y_train = one_hot(y_train_id)\n",
    "    y_valid = one_hot(y_valid_id)\n",
    "    \n",
    "    # History:\n",
    "    # At first you should only use the current image as input to your network to learn the next action. Then the input states\n",
    "    # have shape (96, 96,1). Later, add a history of the last N images to your state so that a state has shape (96, 96, N).\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_valid, n_minibatches, batch_size, lr, model_dir=\"./models\", tensorboard_dir=\"./tensorboard\"):\n",
    "    \n",
    "    # create result and model folders\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)  \n",
    " \n",
    "    print(\"... train model\")\n",
    "\n",
    "\n",
    "    # TODO: specify your neural network in model.py \n",
    "    agent = Model(...)\n",
    "    \n",
    "    tensorboard_eval = Evaluation(tensorboard_dir)\n",
    "\n",
    "    # TODO: implement the training\n",
    "    # \n",
    "    # 1. write a method sample_minibatch and perform an update step\n",
    "    # 2. compute training/ validation accuracy and loss for the batch and visualize them with tensorboard. You can watch the progress of\n",
    "    #    your training in your web browser\n",
    "    # \n",
    "    # training loop\n",
    "    # for i in range(n_minibatches):\n",
    "    #     ...\n",
    "    #     tensorboard_eval.write_episode_data(...)\n",
    "      \n",
    "    # TODO: save your agent\n",
    "    # model_dir = agent.save(os.path.join(model_dir, \"agent.ckpt\"))\n",
    "    # print(\"Model saved in file: %s\" % model_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # read data    \n",
    "    X_train, y_train, X_valid, y_valid = read_data(\"./data\")\n",
    "\n",
    "    # preprocess data\n",
    "    X_train, y_train, X_valid, y_valid = preprocessing(X_train, y_train, X_valid, y_valid, history_length=1)\n",
    "    print(X_train.shape)\n",
    "    plt.imshow(X_train[50,:,:], cmap = 'gray')\n",
    "    plt.show()\n",
    "    # train model (you can change the parameters!)\n",
    "    #train_model(X_train, y_train, X_valid, n_minibatches=100000, batch_size=64, lr=0.0001)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jiangxing_juhua = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13496, 96, 96, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train_history = np.zeros((X_train.shape[0]-jiangxing_juhua+1, jiangxing_juhua, X_train.shape[1], X_train.shape[2]))\n",
    "for i in range(X_train_history.shape[0]):\n",
    "    X_train_history[i] = X_train[i:i+jiangxing_juhua,:,:]\n",
    "X_train_history = X_train_history.transpose(0,2,3,1)\n",
    "print(X_train_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-09ab985faf45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "b = np.array([1,2,3])\n",
    "index = np.random.permutation(a.shape[0])\n",
    "a_new, b_new = a[index], b[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
