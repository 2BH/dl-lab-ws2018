{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhzhang/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main function\n",
      "... read data\n"
     ]
    }
   ],
   "source": [
    "# %load train_agent.py\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Model\n",
    "from utils import *\n",
    "from tensorboard_evaluation import Evaluation\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_data(datasets_dir=\"./data\", frac = 0.1):\n",
    "    \"\"\"\n",
    "    This method reads the states and actions recorded in drive_manually.py \n",
    "    and splits it into training/ validation set.\n",
    "    \"\"\"\n",
    "    print(\"... read data\")\n",
    "    data_file = os.path.join(datasets_dir, 'data.pkl.gzip')\n",
    "  \n",
    "    f = gzip.open(data_file,'rb')\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    # get images as features and actions as targets\n",
    "    X = np.array(data[\"state\"]).astype('float32')\n",
    "    y = np.array(data[\"action\"]).astype('float32')\n",
    "\n",
    "    # split data into training and validation set\n",
    "    n_samples = len(data[\"state\"])\n",
    "    X_train, y_train = X[:int((1-frac) * n_samples)], y[:int((1-frac) * n_samples)]\n",
    "    X_valid, y_valid = X[int((1-frac) * n_samples):], y[int((1-frac) * n_samples):]\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def data_augmentation(X_train, y_train_id):\n",
    "    # left:\n",
    "    left_indices = (y_train_id == LEFT)\n",
    "    # right:\n",
    "    right_indices = (y_train_id == RIGHT)\n",
    "    X_new_left_data = np.flip(X_train[left_indices], axis=2)\n",
    "    X_new_right_data = np.flip(X_train[right_indices], axis=2)\n",
    "    y_new_left_data = np.zeros((X_new_left_data.shape[0])) + RIGHT\n",
    "    y_new_right_data = np.zeros((X_new_right_data.shape[0])) + LEFT\n",
    "    X_train_n = np.concatenate((X_train, X_new_left_data, X_new_right_data), axis=0)\n",
    "    y_train_id_n = np.concatenate((y_train_id, y_new_left_data, y_new_right_data), axis=0)\n",
    "    \n",
    "    return X_train_n, y_train_id_n\n",
    "\n",
    "def id_to_action(labels_id):\n",
    "    classes = 3\n",
    "    labels_action = np.zeros((labels_id.shape[0], classes))\n",
    "    labels_action[labels_id==LEFT] = [-1.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==RIGHT] = [1.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==STRAIGHT] = [0.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==ACCELERATE] = [0.0, 1.0, 0.0]\n",
    "    labels_action[labels_id==BRAKE] = [0.0, 0.0, 0.2]\n",
    "    return labels_action\n",
    "\n",
    "def uniform_sampling(X_train, y_train_id_n, num_samples):\n",
    "    n = X_train.shape[0]\n",
    "    weights = np.zeros(n)\n",
    "    left_indices = y_train_id_n == LEFT\n",
    "    weights[y_train_id_n == LEFT] = n / np.sum(left_indices)\n",
    "    right_indices = y_train_id_n == RIGHT\n",
    "    weights[y_train_id_n == RIGHT] = n / np.sum(right_indices)\n",
    "    straight_indices = y_train_id_n == STRAIGHT\n",
    "    weights[y_train_id_n == STRAIGHT] = n / np.sum(straight_indices)\n",
    "    acce_indices = y_train_id_n == ACCELERATE\n",
    "    weights[y_train_id_n == ACCELERATE] = n / np.sum(acce_indices)\n",
    "    brake_indices = y_train_id_n == BRAKE\n",
    "    weights[y_train_id_n == BRAKE] = n / np.sum(brake_indices)\n",
    "    weights = weights / np.sum(weights)\n",
    "    samples_indices = np.random.choice(np.arange(n), num_samples, p = weights)\n",
    "    \n",
    "    return X_train[samples_indices], y_train_id_n[samples_indices]\n",
    "\n",
    "\n",
    "def sample_minibatch(X, y, b=0, batch_size=64, history_length=1):\n",
    "    # get small batch\n",
    "    X_batch = np.zeros((batch_size, X.shape[1], X.shape[2], history_length))\n",
    "    for i in range(history_length):\n",
    "        X_batch[:,:,:,i] = X[i+b*batch_size:i+(b+1)*batch_size]\n",
    "    y_batch = y[history_length-1+b*batch_size:history_length-1+(b+1)*batch_size]\n",
    "    # shuffle data slightly (because it's in the batch)\n",
    "    index = np.random.permutation(batch_size)\n",
    "    # X_batch, y_batch = X_train[b*batch_size:(b+1)*batch_size], y_train[b*batch_size:(b+1)*batch_size]\n",
    "    X_batch, y_batch = X_batch[index], y_batch[index]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "\n",
    "def preprocessing(X_train, y_train, X_valid, y_valid, history_length=1):\n",
    "\n",
    "    # TODO: preprocess your data here.\n",
    "    # 1. convert the images in X_train/X_valid to gray scale. If you use rgb2gray() from utils.py, the output shape (96, 96, 1)\n",
    "    # 2. you can either train your model with continous actions (as you get them from read_data) using regression\n",
    "    #    or you discretize the action space using action_to_id() from utils.py. If you discretize them, you'll maybe find one_hot() \n",
    "    #    useful and you may want to return X_train_unhot ... as well.\n",
    "    X_train = rgb2gray(X_train)\n",
    "    X_valid = rgb2gray(X_valid)\n",
    "    # history:\n",
    "    \n",
    "    # X_train_history = np.zeros((X_train.shape[0]-history_length+1, history_length, X_train.shape[1], X_train.shape[2]))\n",
    "    # for i in range(X_train_history.shape[0]):\n",
    "    #     X_train_history[i] = X_train[i:i+history_length,:,:]\n",
    "    # X_train_history = X_train_history.transpose(0,2,3,1)\n",
    "    \n",
    "    # X_valid_history = np.zeros((X_valid.shape[0]-history_length+1, history_length, X_valid.shape[1], X_valid.shape[2]))\n",
    "    # for i in range(X_valid_history.shape[0]):\n",
    "    #     X_valid_history[i] = X_valid[i:i+history_length,:,:]\n",
    "    # X_valid_history = X_valid_history.transpose(0,2,3,1)\n",
    "    \n",
    "    # y_valid_history = y_valid[history_length-1:]\n",
    "    # discretize actions\n",
    "    # y_train_id = np.zeros(y_train.shape[0]-history_length+1)\n",
    "    # y_valid_id = np.zeros(y_valid.shape[0]-history_length+1)\n",
    "    \n",
    "    # data augmentation\n",
    "    #for i in range(y_train.shape[0]-history_length+1):\n",
    "    #    y_train_id[i] = action_to_id(y_train[i+history_length-1])\n",
    " \n",
    "    # X_train_n, y_train_id_n = data_augmentation(X_train, y_train_id)\n",
    "    # X_train_sampled, y_train_id_sampled = uniform_sampling(X_train, y_train_id, num_samples=12000)\n",
    "\n",
    "    # y_train_action = id_to_action(y_train_id_sampled)\n",
    "    # History:\n",
    "    # At first you should only use the current image as input to your network to learn the next action. Then the input states\n",
    "    # have shape (96, 96,1). Later, add a history of the last N images to your state so that a state has shape (96, 96, N).\n",
    "    \n",
    "    # return X_train_sampled, y_train_action, X_valid_history, y_valid_history\n",
    "    # return X_train_sampled, y_train_action, X_valid, y_valid\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def train_model(X_train, y_train, X_valid, y_valid, epochs, batch_size, lr, history_length=1, model_dir=\"./models\", tensorboard_dir=\"./tensorboard\"):\n",
    "    \n",
    "    # create result and model folders\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)  \n",
    " \n",
    "    print(\"... train model\")\n",
    "\n",
    "\n",
    "    # TODO: specify your neural network in model.py \n",
    "    agent = Model(learning_rate=lr, history_length=history_length)\n",
    "    init = tf.global_variables_initializer()\n",
    "    agent.sess.run(init)\n",
    "    tensorboard_eval = Evaluation(tensorboard_dir)\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    # y_pred = tf.argmax(agent.output, 1)\n",
    "    # tf.add_to_collection('pred_network', y_pred)\n",
    "    # correct_pred = tf.equal(agent.y_pred, tf.argmax(agent.y_label, 1))\n",
    "    # calculate train and valid accuracy\n",
    "    # accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "    # init all variables\n",
    "    \n",
    "    # TODO: implement the training\n",
    "    # \n",
    "    # 1. write a method sample_minibatch and perform an update step\n",
    "    # 2. compute training/ validation accuracy and loss for the batch and visualize them with tensorboard. You can watch the progress of\n",
    "    #    your training in your web browser\n",
    "    \n",
    "    total_batch_num = (X_train.shape[0] - history_length + 1) // batch_size;\n",
    "    total_batch_num_valid = (X_valid.shape[0] - history_length + 1)// batch_size;\n",
    "    # training loop\n",
    "    train_cost = np.zeros((epochs))\n",
    "    # train_accuracy = np.zeros((epochs))\n",
    "    valid_cost = np.zeros((epochs))\n",
    "    for epoch in range(epochs):\n",
    "        # shuffle the data set\n",
    "        # index = np.random.permutation(X_train.shape[0])\n",
    "        # X_train, y_train = X_train[index], y_train[index]\n",
    "        # print(X_train.shape)\n",
    "        for b in range(total_batch_num):\n",
    "            # select the batch data\n",
    "            X_batch, y_batch = sample_minibatch(X_train, y_train, b, batch_size, history_length)\n",
    "            # compute the cost\n",
    "            _ , temp_cost = agent.sess.run([agent.optimizer, agent.cost], feed_dict={agent.x_input:X_batch, agent.y_label:y_batch})\n",
    "\n",
    "        # training cost\n",
    "        for b in range(total_batch_num):\n",
    "            X_batch, y_batch = sample_minibatch(X_train, y_train, b, batch_size, history_length)\n",
    "            train_cost[epoch] += agent.sess.run(agent.cost, feed_dict={agent.x_input: X_batch, agent.y_label: y_batch})\n",
    "\n",
    "        # validation cost\n",
    "        for b in range(total_batch_num_valid):\n",
    "            X_valid_batch, y_valid_batch = sample_minibatch(X_valid, y_valid, b, batch_size, history_length)\n",
    "            valid_cost[epoch] += agent.sess.run(agent.cost, feed_dict={agent.x_input:X_valid_batch, agent.y_label:y_valid_batch})\n",
    "        train_cost[epoch] = train_cost[epoch] / total_batch_num\n",
    "        valid_cost[epoch] = valid_cost[epoch] / total_batch_num_valid\n",
    "        print(\"[%d/%d]: train_cost: %.4f, valid_cost: %.4f\" %(epoch+1, epochs, train_cost[epoch], valid_cost[epoch]))\n",
    "        eval_dict = {\"train\":train_cost[epoch], \"valid\":valid_cost[epoch]}\n",
    "        tensorboard_eval.write_episode_data(epoch, eval_dict)\n",
    "      \n",
    "    # TODO: save your agent\n",
    "    agent.save(os.path.join(model_dir, \"agent.ckpt\"))\n",
    "    print(model_dir)\n",
    "    print(\"Model saved in file: %s\" % model_dir)\n",
    "    agent.sess.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"main function\")\n",
    "    # read data    \n",
    "    X_train, y_train, X_valid, y_valid = read_data(\"./data\")\n",
    "    history_length = 5\n",
    "    # preprocess data\n",
    "    X_train, y_train, X_valid, y_valid = preprocessing(X_train, y_train, X_valid, y_valid, history_length)\n",
    "    # train model (you can change the parameters!)\n",
    "    # train_model(X_train, y_train, X_valid, y_valid, history_length=history_length, epochs=20, batch_size=64, lr=0.0004)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_minibatch(X_train, y_train, b=0, batch_size=64, history_length=1):\n",
    "    X_batch = np.zeros((batch_size, X_train.shape[1], X_train.shape[2], history_length))\n",
    "    for i in range(history_length):\n",
    "        X_batch[:,:,:,i] = X_train[i+b*batch_size:i+(b+1)*batch_size]\n",
    "    y_batch = y_train[history_length-1+b*batch_size:history_length-1+(b+1)*batch_size]\n",
    "    index = np.random.permutation(batch_size)\n",
    "    X_batch, y_batch = X_batch[index], y_batch[index]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "X_batch, y_batch = sample_minibatch(X_valid, y_valid, b=0, batch_size=64, history_length=5)\n",
    "print(X_batch.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[history_length-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b553128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_train_id = np.zeros(y_train.shape[0])\n",
    "for i in range(y_train.shape[0]):\n",
    "    y_train_id[i] = action_to_id(y_train[i])\n",
    "plt.hist(y_train_id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "print(action_to_id(y_train[426]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[426]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(y_train[426], [0.0, 0.0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train_id == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
